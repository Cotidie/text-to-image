services:
  base:
    ports:
      - "${PORT}:${PORT}"
    env_file:
      - .env
    volumes:
      - model-cache:/etc/cache
      - ${MODEL_PATH}:/etc/model
    environment:
      - HF_HOME=/etc/cache
      - MODEL_PATH=/etc/model  # OVERRIDE on container runtime
    restart: unless-stopped
    profiles: ["base-only"]    # This service is abstract and will be inherited

  nvidia:
    extends: base
    image: makelab/backend:image-generation-nvidia
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BASE_IMAGE: pytorch/pytorch:2.9.1-cuda13.0-cudnn9-runtime
    container_name: server-image-generation
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles: ["nvidia"]

  amd:
    extends: base
    image: makelab/backend:image-generation-amd
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BASE_IMAGE: rocm/pytorch:rocm7.1_ubuntu24.04_py3.12_pytorch_release_2.8.0
    container_name: server-image-generation
    devices:
      - /dev/dri:/dev/dri
      - /dev/kfd:/dev/kfd
    security_opt:
      - seccomp=unconfined
    group_add:
      - video
    profiles: ["amd"]

volumes:
  model-cache: